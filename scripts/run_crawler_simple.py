#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€åŒ–ç‰ˆå°çº¢ä¹¦çˆ¬è™« - ä¸“ä¸º GitHub Actions ç¯å¢ƒä¼˜åŒ–
"""

import os
import sys
import argparse
import subprocess
from datetime import datetime


def get_default_keywords():
    """è·å–é»˜è®¤å…³é”®è¯"""
    default_keywords = "æ™®æ‹‰æ,å¥èº«,ç‘œä¼½"
    print(f"ğŸ“‹ ä½¿ç”¨é»˜è®¤å…³é”®è¯: {default_keywords}")
    return default_keywords


def create_main_py_if_missing():
    """å¦‚æœ main.py ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€åŒ–ç‰ˆæœ¬"""
    media_crawler_dir = 'core/media_crawler'
    main_py = os.path.join(media_crawler_dir, 'main.py')

    if not os.path.exists(main_py):
        print(f"ğŸ”§ åˆ›å»º main.py æ–‡ä»¶: {main_py}")

        main_py_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MediaCrawler ä¸»ç¨‹åº - GitHub Actions ç®€åŒ–ç‰ˆ
"""

import argparse
import sys
import os
from datetime import datetime

def main():
    parser = argparse.ArgumentParser(description='MediaCrawler')
    parser.add_argument('--platform', default='xhs')
    parser.add_argument('--lt', default='cookie')
    parser.add_argument('--type', default='search')
    parser.add_argument('--keywords', required=True)

    args = parser.parse_args()

    print(f"MediaCrawler å¯åŠ¨å‚æ•°:")
    print(f"  å¹³å°: {args.platform}")
    print(f"  ç™»å½•ç±»å‹: {args.lt}")
    print(f"  ç±»å‹: {args.type}")
    print(f"  å…³é”®è¯: {args.keywords}")

    # åœ¨ GitHub Actions ç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬æ— æ³•çœŸæ­£è¿è¡Œçˆ¬è™«
    # æ‰€ä»¥è¿™é‡Œåªæ˜¯æ¨¡æ‹Ÿè¿è¡Œ
    print("âš ï¸  åœ¨ GitHub Actions ç¯å¢ƒä¸­æ— æ³•è¿è¡ŒçœŸå®çˆ¬è™«")
    print("ğŸ’¡ å°†åœ¨åç»­æ­¥éª¤ä¸­åˆ›å»ºç¤ºä¾‹æ•°æ®")

    return 0

if __name__ == '__main__':
    sys.exit(main())
'''

        try:
            os.makedirs(media_crawler_dir, exist_ok=True)
            with open(main_py, 'w', encoding='utf-8') as f:
                f.write(main_py_content)
            print(f"âœ… main.py å·²åˆ›å»º")
            return True
        except Exception as e:
            print(f"âŒ åˆ›å»º main.py å¤±è´¥: {e}")
            return False

    return True


def run_mediacrawler(keywords, limit=100):
    """è¿è¡Œ MediaCrawlerï¼ˆGitHub Actions ä¼˜åŒ–ç‰ˆï¼‰"""
    print(f"ğŸš€ å¯åŠ¨ MediaCrawler...")
    print(f"   å…³é”®è¯: {keywords}")
    print(f"   æ•°é‡é™åˆ¶: {limit}")

    # åœ¨ GitHub Actions ç¯å¢ƒä¸­ï¼Œå…ˆå°è¯•çœŸå®çˆ¬å–
    # å¦‚æœå¤±è´¥å†ä½¿ç”¨å¤‡ç”¨æ•°æ®
    if os.environ.get('GITHUB_ACTIONS') == 'true':
        print("ğŸ”§ æ£€æµ‹åˆ° GitHub Actions ç¯å¢ƒ")
        print("ğŸš€ å°è¯•çœŸå®çˆ¬å–ï¼ˆå¦‚æœ Cookie æœ‰æ•ˆï¼‰")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸ç›´æ¥è¿”å› False

    # æœ¬åœ°ç¯å¢ƒå°è¯•è¿è¡Œ MediaCrawler
    media_crawler_dir = 'core/media_crawler'

    if not os.path.exists(media_crawler_dir):
        print(f"âŒ MediaCrawler ç›®å½•ä¸å­˜åœ¨: {media_crawler_dir}")
        return False

    # ç¡®ä¿ main.py å­˜åœ¨
    if not create_main_py_if_missing():
        return False

    # æ£€æŸ¥ main.py æ˜¯å¦å­˜åœ¨
    main_py = os.path.join(media_crawler_dir, 'main.py')
    if not os.path.exists(main_py):
        print(f"âŒ main.py ä»ç„¶ä¸å­˜åœ¨: {main_py}")
        return False
    
    try:
        # æ„å»ºå‘½ä»¤ (æ ¹æ® MediaCrawler çš„å®é™…å‚æ•°)
        cmd = [
            sys.executable, 'main.py',
            '--platform', 'xhs',
            '--lt', 'cookie',
            '--type', 'search',
            '--keywords', keywords
            # æ³¨æ„ï¼šMediaCrawler å¯èƒ½ä¸æ”¯æŒ --crawl-count å‚æ•°
            # æ•°é‡é™åˆ¶å¯èƒ½éœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®
        ]
        
        print(f"ğŸ”§ æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
        print(f"ğŸ”§ å·¥ä½œç›®å½•: {os.path.abspath(media_crawler_dir)}")
        
        # è¿è¡Œå‘½ä»¤
        result = subprocess.run(
            cmd,
            cwd=media_crawler_dir,
            capture_output=True,
            text=True,
            timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
        )
        
        print(f"ğŸ“Š è¿”å›ç : {result.returncode}")
        
        if result.stdout:
            print("ğŸ“¤ æ ‡å‡†è¾“å‡º:")
            print(result.stdout)
        
        if result.stderr:
            print("ğŸ“¤ é”™è¯¯è¾“å‡º:")
            print(result.stderr)
        
        if result.returncode == 0:
            print("âœ… MediaCrawler è¿è¡ŒæˆåŠŸ")
            return True
        else:
            print(f"âŒ MediaCrawler è¿è¡Œå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
            return False
            
    except subprocess.TimeoutExpired:
        print("â° MediaCrawler è¿è¡Œè¶…æ—¶")
        return False
    except Exception as e:
        print(f"âŒ è¿è¡Œ MediaCrawler æ—¶å‡ºé”™: {e}")
        return False


def check_output_files():
    """æ£€æŸ¥è¾“å‡ºæ–‡ä»¶"""
    print("ğŸ“ æ£€æŸ¥è¾“å‡ºæ–‡ä»¶...")
    
    data_dirs = [
        'core/media_crawler/data/xhs',
        'data/xhs',
        'output'
    ]
    
    found_files = []
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]
            if files:
                print(f"âœ… åœ¨ {data_dir} æ‰¾åˆ° {len(files)} ä¸ª CSV æ–‡ä»¶:")
                for file in sorted(files)[-3:]:  # æ˜¾ç¤ºæœ€æ–°çš„3ä¸ªæ–‡ä»¶
                    file_path = os.path.join(data_dir, file)
                    file_size = os.path.getsize(file_path)
                    print(f"   ğŸ“„ {file} ({file_size} bytes)")
                    found_files.append(file_path)
    
    if found_files:
        print(f"âœ… æ€»å…±æ‰¾åˆ° {len(found_files)} ä¸ªè¾“å‡ºæ–‡ä»¶")
        return True
    else:
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•è¾“å‡ºæ–‡ä»¶")
        return False





def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç®€åŒ–ç‰ˆå°çº¢ä¹¦çˆ¬è™« - GitHub Actions ä¼˜åŒ–ç‰ˆ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        '--keyword',
        type=str,
        help='æœç´¢å…³é”®è¯ (å¦‚ä¸æä¾›åˆ™ä» config/keywords.txt è¯»å–)'
    )
    parser.add_argument(
        '--limit',
        type=int,
        default=50,
        help='çˆ¬å–æ•°é‡é™åˆ¶ (é»˜è®¤: 50)'
    )

    
    args = parser.parse_args()
    
    print("=" * 60)
    print("ğŸ•·ï¸  å°çº¢ä¹¦çˆ¬è™« (GitHub Actions ç®€åŒ–ç‰ˆ)")
    print("=" * 60)
    
    # å¤„ç†å…³é”®è¯
    if args.keyword:
        keywords = args.keyword
        print(f"ğŸ¯ ä½¿ç”¨å‘½ä»¤è¡Œå…³é”®è¯: {keywords}")
    else:
        keywords = get_default_keywords()
    
    print(f"ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"   å…³é”®è¯: {keywords}")
    print(f"   æ•°é‡é™åˆ¶: {args.limit}")
    print(f"   å½“å‰ç›®å½•: {os.getcwd()}")
    print()
    
    # å°è¯•è¿è¡Œçˆ¬è™«
    success = run_mediacrawler(keywords, args.limit)
    
    # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶
    has_output = check_output_files()
    
    if not success or not has_output:
        print("âŒ çˆ¬å–å¤±è´¥ï¼Œæ²¡æœ‰è·å–åˆ°ä»»ä½•çœŸå®æ•°æ®")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("   - Cookie å·²è¿‡æœŸï¼Œéœ€è¦æ›´æ–°")
        print("   - å°çº¢ä¹¦ API ç«¯ç‚¹å·²å˜æ›´")
        print("   - ç½‘ç»œè¿æ¥é—®é¢˜")
        print("   - åçˆ¬æœºåˆ¶é˜»æ­¢äº†è¯·æ±‚")
    
    if has_output:
        print("\nâœ… çˆ¬è™«ä»»åŠ¡å®Œæˆ!")
        print("ğŸ“ æ•°æ®æ–‡ä»¶å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥è¿›è¡Œåç»­åˆ†æ")
        return True
    else:
        print("\nâŒ çˆ¬è™«ä»»åŠ¡å¤±è´¥!")
        print("ğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ Cookie é…ç½®")
        print("ğŸš« ä¸ä¼šç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ï¼Œåªä½¿ç”¨çœŸå®æ•°æ®è¿›è¡Œåˆ†æ")
        return False


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
