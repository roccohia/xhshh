#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç«å“ç¬”è®°åˆ†ææ¨¡å—
åˆ†æå°çº¢ä¹¦ç¬”è®°çš„äº’åŠ¨æ•°æ®ï¼Œè¯†åˆ«é«˜è´¨é‡å†…å®¹å’Œå†…å®¹ç±»å‹
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import re


def classify_content_type(title, desc):
    """æ ¹æ®æ ‡é¢˜å’Œæè¿°åˆ†ç±»å†…å®¹ç±»å‹"""
    title = str(title).lower()
    desc = str(desc).lower()
    content = f"{title} {desc}"
    
    # å®šä¹‰å…³é”®è¯æ¨¡å¼
    patterns = {
        'äº²èº«ä½“éªŒ': [
            'æˆ‘çš„', 'äº²æµ‹', 'ä½“éªŒ', 'è¯•ç”¨', 'ä½¿ç”¨æ„Ÿå—', 'çœŸå®æ„Ÿå—',
            'ç¬¬ä¸€æ¬¡', 'åˆä½“éªŒ', 'å°è¯•', 'æ„Ÿå—', 'å¿ƒå¾—', 'æ—¥è®°'
        ],
        'ç§è‰æ¨è': [
            'æ¨è', 'å®‰åˆ©', 'ç§è‰', 'å¿…ä¹°', 'å¥½ç”¨', 'å€¼å¾—', 'å¼ºçƒˆæ¨è',
            'ä¸è¸©é›·', 'é—­çœ¼å…¥', 'å›è´­', 'çˆ±ç”¨', 'å¥½ç‰©'
        ],
        'æ•™ç¨‹æŒ‡å¯¼': [
            'æ•™ç¨‹', 'æ•™å­¦', 'æ€ä¹ˆ', 'å¦‚ä½•', 'æ–¹æ³•', 'æ­¥éª¤', 'æŠ€å·§',
            'å…¥é—¨', 'é›¶åŸºç¡€', 'æ–°æ‰‹', 'æŒ‡å—', 'æ”»ç•¥'
        ],
        'å¯¹æ¯”æµ‹è¯„': [
            'vs', 'å¯¹æ¯”', 'æµ‹è¯„', 'è¯„æµ‹', 'åŒºåˆ«', 'å“ªä¸ªå¥½', 'é€‰æ‹©',
            'æ¯”è¾ƒ', 'æµ‹è¯•', 'æ¨ªè¯„', 'å¯¹å†³'
        ],
        'çŸ¥è¯†ç§‘æ™®': [
            'ç§‘æ™®', 'çŸ¥è¯†', 'åŸç†', 'ä¸ºä»€ä¹ˆ', 'ä»€ä¹ˆæ˜¯', 'è§£æ',
            'æ­ç§˜', 'çœŸç›¸', 'è¯¯åŒº', 'æ³¨æ„äº‹é¡¹'
        ],
        'æ‰“å¡åˆ†äº«': [
            'æ‰“å¡', 'æ—¥å¸¸', 'vlog', 'è®°å½•', 'åˆ†äº«', 'ä»Šå¤©',
            'åšæŒ', 'ç¬¬å‡ å¤©', 'è¿›æ­¥', 'å˜åŒ–'
        ]
    }
    
    # è®¡ç®—æ¯ç§ç±»å‹çš„åŒ¹é…åˆ†æ•°
    scores = {}
    for content_type, keywords in patterns.items():
        score = sum(1 for keyword in keywords if keyword in content)
        scores[content_type] = score
    
    # è¿”å›å¾—åˆ†æœ€é«˜çš„ç±»å‹
    if max(scores.values()) > 0:
        return max(scores, key=scores.get)
    else:
        return 'å…¶ä»–'


def calculate_engagement_metrics(df):
    """è®¡ç®—äº’åŠ¨æŒ‡æ ‡"""
    print("ğŸ“Š è®¡ç®—äº’åŠ¨æŒ‡æ ‡...")
    
    # è½¬æ¢æ•°å€¼ç±»å‹
    numeric_columns = ['liked_count', 'collected_count', 'comment_count', 'share_count']
    for col in numeric_columns:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # è®¡ç®—æ€»äº’åŠ¨æ•°
    df['total_engagement'] = (
        df.get('liked_count', 0) + 
        df.get('collected_count', 0) + 
        df.get('comment_count', 0) + 
        df.get('share_count', 0)
    )
    
    # è®¡ç®—äº’åŠ¨ç‡ (å‡è®¾æ›å…‰é‡ä¸ºæ€»äº’åŠ¨æ•°çš„10-50å€)
    # è¿™é‡Œä½¿ç”¨ä¸€ä¸ªä¼°ç®—å…¬å¼
    df['estimated_views'] = df['total_engagement'] * np.random.uniform(15, 35, len(df))
    df['engagement_rate'] = (df['total_engagement'] / df['estimated_views'] * 100).round(2)
    
    # è®¡ç®—æ”¶è—ç‡
    df['collect_rate'] = (df.get('collected_count', 0) / df['total_engagement'] * 100).round(2)
    df['collect_rate'] = df['collect_rate'].fillna(0)
    
    # è®¡ç®—è¯„è®ºç‡
    df['comment_rate'] = (df.get('comment_count', 0) / df['total_engagement'] * 100).round(2)
    df['comment_rate'] = df['comment_rate'].fillna(0)
    
    return df


def analyze_time_patterns(df):
    """åˆ†æå‘å¸ƒæ—¶é—´æ¨¡å¼"""
    print("â° åˆ†æå‘å¸ƒæ—¶é—´æ¨¡å¼...")
    
    if 'time' not in df.columns:
        return df
    
    # è½¬æ¢æ—¶é—´æˆ³
    df['publish_datetime'] = pd.to_datetime(df['time'], unit='ms', errors='coerce')
    df['publish_date'] = df['publish_datetime'].dt.date
    df['publish_hour'] = df['publish_datetime'].dt.hour
    df['publish_weekday'] = df['publish_datetime'].dt.day_name()
    df['publish_month'] = df['publish_datetime'].dt.month
    
    # è®¡ç®—å‘å¸ƒå¤©æ•°
    if not df['publish_datetime'].isna().all():
        latest_date = df['publish_datetime'].max()
        df['days_since_publish'] = (latest_date - df['publish_datetime']).dt.days
    
    return df


def identify_high_performance_content(df, top_n=20):
    """è¯†åˆ«é«˜è¡¨ç°å†…å®¹"""
    print(f"ğŸ† è¯†åˆ«å‰ {top_n} ä¸ªé«˜è¡¨ç°å†…å®¹...")
    
    # æŒ‰äº’åŠ¨ç‡æ’åº
    high_engagement = df.nlargest(top_n, 'engagement_rate').copy()
    
    # æŒ‰æ€»äº’åŠ¨æ•°æ’åº
    high_total = df.nlargest(top_n, 'total_engagement').copy()
    
    # æŒ‰æ”¶è—ç‡æ’åº
    high_collect = df.nlargest(top_n, 'collect_rate').copy()
    
    return {
        'high_engagement': high_engagement,
        'high_total': high_total,
        'high_collect': high_collect
    }


def generate_competitor_report(df, output_dir):
    """ç”Ÿæˆç«å“åˆ†ææŠ¥å‘Š"""
    print("ğŸ“‹ ç”Ÿæˆç«å“åˆ†ææŠ¥å‘Š...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # åŸºç¡€ç»Ÿè®¡
    stats = {
        'æ€»ç¬”è®°æ•°': len(df),
        'å¹³å‡ç‚¹èµæ•°': df['liked_count'].mean(),
        'å¹³å‡æ”¶è—æ•°': df['collected_count'].mean(),
        'å¹³å‡è¯„è®ºæ•°': df['comment_count'].mean(),
        'å¹³å‡äº’åŠ¨ç‡': df['engagement_rate'].mean(),
        'æœ€é«˜äº’åŠ¨ç‡': df['engagement_rate'].max(),
        'æœ€é«˜ç‚¹èµæ•°': df['liked_count'].max()
    }
    
    # å†…å®¹ç±»å‹åˆ†å¸ƒ
    content_type_dist = df['content_type'].value_counts()
    
    # ç”¨æˆ·åˆ†æ
    user_stats = df.groupby('nickname').agg({
        'total_engagement': ['count', 'mean', 'sum'],
        'engagement_rate': 'mean'
    }).round(2)
    
    user_stats.columns = ['å‘å¸ƒæ•°é‡', 'å¹³å‡äº’åŠ¨æ•°', 'æ€»äº’åŠ¨æ•°', 'å¹³å‡äº’åŠ¨ç‡']
    user_stats = user_stats.sort_values('æ€»äº’åŠ¨æ•°', ascending=False).head(20)
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = os.path.join(output_dir, f'competitor_report_{timestamp}.txt')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("å°çº¢ä¹¦ç«å“ç¬”è®°åˆ†ææŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        f.write("ğŸ“Š åŸºç¡€ç»Ÿè®¡\n")
        f.write("-" * 30 + "\n")
        for key, value in stats.items():
            f.write(f"{key}: {value:.2f}\n")
        
        f.write("\nğŸ“‹ å†…å®¹ç±»å‹åˆ†å¸ƒ\n")
        f.write("-" * 30 + "\n")
        for content_type, count in content_type_dist.items():
            percentage = count / len(df) * 100
            f.write(f"{content_type}: {count}ç¯‡ ({percentage:.1f}%)\n")
        
        f.write("\nğŸ‘¥ æ´»è·ƒç”¨æˆ·TOP20\n")
        f.write("-" * 30 + "\n")
        f.write(user_stats.to_string())
        
        f.write(f"\n\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    print(f"ğŸ“‹ ç«å“åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    return stats, content_type_dist, user_stats


def create_visualizations(df, output_dir):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    print("ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # 1. äº’åŠ¨æŒ‡æ ‡åˆ†å¸ƒå›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # ç‚¹èµæ•°åˆ†å¸ƒ
    axes[0, 0].hist(df['liked_count'], bins=30, alpha=0.7, color='skyblue')
    axes[0, 0].set_title('ç‚¹èµæ•°åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('ç‚¹èµæ•°')
    axes[0, 0].set_ylabel('é¢‘æ¬¡')
    
    # æ”¶è—æ•°åˆ†å¸ƒ
    axes[0, 1].hist(df['collected_count'], bins=30, alpha=0.7, color='lightgreen')
    axes[0, 1].set_title('æ”¶è—æ•°åˆ†å¸ƒ')
    axes[0, 1].set_xlabel('æ”¶è—æ•°')
    axes[0, 1].set_ylabel('é¢‘æ¬¡')
    
    # äº’åŠ¨ç‡åˆ†å¸ƒ
    axes[1, 0].hist(df['engagement_rate'], bins=30, alpha=0.7, color='orange')
    axes[1, 0].set_title('äº’åŠ¨ç‡åˆ†å¸ƒ')
    axes[1, 0].set_xlabel('äº’åŠ¨ç‡ (%)')
    axes[1, 0].set_ylabel('é¢‘æ¬¡')
    
    # å†…å®¹ç±»å‹åˆ†å¸ƒ
    content_counts = df['content_type'].value_counts()
    axes[1, 1].pie(content_counts.values, labels=content_counts.index, autopct='%1.1f%%')
    axes[1, 1].set_title('å†…å®¹ç±»å‹åˆ†å¸ƒ')
    
    plt.tight_layout()
    chart1_path = os.path.join(output_dir, f'engagement_analysis_{timestamp}.png')
    plt.savefig(chart1_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. æ—¶é—´è¶‹åŠ¿å›¾
    if 'publish_datetime' in df.columns and not df['publish_datetime'].isna().all():
        fig, axes = plt.subplots(2, 1, figsize=(15, 10))
        
        # æŒ‰æ—¥æœŸç»Ÿè®¡å‘å¸ƒé‡
        daily_posts = df.groupby(df['publish_datetime'].dt.date).size()
        axes[0].plot(daily_posts.index, daily_posts.values, marker='o')
        axes[0].set_title('æ¯æ—¥å‘å¸ƒé‡è¶‹åŠ¿')
        axes[0].set_xlabel('æ—¥æœŸ')
        axes[0].set_ylabel('å‘å¸ƒæ•°é‡')
        axes[0].tick_params(axis='x', rotation=45)
        
        # æŒ‰å°æ—¶ç»Ÿè®¡å‘å¸ƒé‡
        hourly_posts = df.groupby('publish_hour').size()
        axes[1].bar(hourly_posts.index, hourly_posts.values, alpha=0.7)
        axes[1].set_title('å‘å¸ƒæ—¶é—´åˆ†å¸ƒ (æŒ‰å°æ—¶)')
        axes[1].set_xlabel('å°æ—¶')
        axes[1].set_ylabel('å‘å¸ƒæ•°é‡')
        
        plt.tight_layout()
        chart2_path = os.path.join(output_dir, f'time_analysis_{timestamp}.png')
        plt.savefig(chart2_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ğŸ“ˆ æ—¶é—´åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {chart2_path}")
    
    print(f"ğŸ“ˆ äº’åŠ¨åˆ†æå›¾è¡¨å·²ä¿å­˜åˆ°: {chart1_path}")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='å°çº¢ä¹¦ç«å“ç¬”è®°åˆ†æå·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python analysis/competitor_analysis.py --input core/media_crawler/data/xhs/1_search_contents_2025-07-02.csv
  python analysis/competitor_analysis.py --input data.csv --top-n 30
        """
    )
    
    parser.add_argument(
        '--input', '-i',
        type=str,
        required=True,
        help='è¾“å…¥çš„ CSV æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        default='output',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: output)'
    )
    parser.add_argument(
        '--top-n', '-n',
        type=int,
        default=20,
        help='åˆ†æå‰ N ä¸ªé«˜è¡¨ç°å†…å®¹ (é»˜è®¤: 20)'
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        sys.exit(1)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    print("=" * 60)
    print("ğŸ† å°çº¢ä¹¦ç«å“ç¬”è®°åˆ†æ")
    print("=" * 60)
    
    try:
        # è¯»å–æ•°æ®
        print(f"ğŸ“– è¯»å–æ•°æ®æ–‡ä»¶: {args.input}")
        df = pd.read_csv(args.input)
        
        print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: {len(df)} æ¡ç¬”è®°")
        
        # æ•°æ®æ¸…ç†
        df = df.fillna('')
        
        # åˆ†ç±»å†…å®¹ç±»å‹
        print("ğŸ·ï¸ åˆ†æå†…å®¹ç±»å‹...")
        df['content_type'] = df.apply(
            lambda row: classify_content_type(row.get('title', ''), row.get('desc', '')),
            axis=1
        )
        
        # è®¡ç®—äº’åŠ¨æŒ‡æ ‡
        df = calculate_engagement_metrics(df)
        
        # åˆ†ææ—¶é—´æ¨¡å¼
        df = analyze_time_patterns(df)
        
        # è¯†åˆ«é«˜è¡¨ç°å†…å®¹
        high_performance = identify_high_performance_content(df, args.top_n)
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜åˆ†æç»“æœ
        main_output = os.path.join(args.output_dir, f'competitor_analysis_{timestamp}.csv')
        
        # é€‰æ‹©è¦ä¿å­˜çš„åˆ—
        output_columns = [
            'title', 'nickname', 'content_type', 'liked_count', 'collected_count',
            'comment_count', 'share_count', 'total_engagement', 'engagement_rate',
            'collect_rate', 'comment_rate'
        ]
        
        # æ·»åŠ æ—¶é—´ç›¸å…³åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        time_columns = ['publish_datetime', 'publish_date', 'publish_hour', 'days_since_publish']
        for col in time_columns:
            if col in df.columns:
                output_columns.append(col)
        
        # æŒ‰äº’åŠ¨ç‡æ’åºå¹¶ä¿å­˜
        df_sorted = df.sort_values('engagement_rate', ascending=False)
        df_sorted[output_columns].to_csv(main_output, index=False, encoding='utf-8-sig')
        print(f"ğŸ“„ ç«å“åˆ†æç»“æœå·²ä¿å­˜åˆ°: {main_output}")
        
        # ä¿å­˜é«˜è¡¨ç°å†…å®¹
        for category, data in high_performance.items():
            category_output = os.path.join(
                args.output_dir, f'{category}_{timestamp}.csv'
            )
            data[output_columns].to_csv(category_output, index=False, encoding='utf-8-sig')
            print(f"ğŸ“„ {category} å·²ä¿å­˜åˆ°: {category_output}")
        
        # ç”ŸæˆæŠ¥å‘Š
        stats, content_dist, user_stats = generate_competitor_report(df, args.output_dir)
        
        # åˆ›å»ºå¯è§†åŒ–
        create_visualizations(df, args.output_dir)
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†æç»“æœç»Ÿè®¡")
        print("=" * 60)
        print(f"ğŸ“ åˆ†æç¬”è®°æ•°é‡: {len(df)}")
        print(f"ğŸ“ˆ å¹³å‡äº’åŠ¨ç‡: {stats['å¹³å‡äº’åŠ¨ç‡']:.2f}%")
        print(f"ğŸ† æœ€é«˜äº’åŠ¨ç‡: {stats['æœ€é«˜äº’åŠ¨ç‡']:.2f}%")
        print(f"ğŸ‘ æœ€é«˜ç‚¹èµæ•°: {int(stats['æœ€é«˜ç‚¹èµæ•°'])}")
        
        print("\nğŸ“‹ å†…å®¹ç±»å‹åˆ†å¸ƒ:")
        for content_type, count in content_dist.head().items():
            percentage = count / len(df) * 100
            print(f"  {content_type}: {count}ç¯‡ ({percentage:.1f}%)")
        
        print("\nâœ… ç«å“åˆ†æå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
