#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Notion å†…å®¹æ—¥å†å¯¼å‡ºæ¨¡å—
ç”Ÿæˆé€‚ç”¨äº Notion å¯¼å…¥çš„å†…å®¹æ—¥å† CSV æ–‡ä»¶
"""

import os
import sys
import argparse
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import random
import glob
import re


def find_latest_analysis_files(output_dir):
    """æŸ¥æ‰¾æœ€æ–°çš„åˆ†ææ–‡ä»¶"""
    files = {}
    
    # æŸ¥æ‰¾å„ç±»åˆ†ææ–‡ä»¶
    patterns = {
        'topic_suggestions': 'topic_suggestions_*.csv',
        'high_engagement': 'high_engagement_*.csv',
        'keywords_analysis': 'keywords_analysis_*.csv'
    }
    
    for file_type, pattern in patterns.items():
        file_pattern = os.path.join(output_dir, pattern)
        matching_files = glob.glob(file_pattern)
        
        if matching_files:
            # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶ï¼ˆæŒ‰æ–‡ä»¶åæ’åºï¼Œé€šå¸¸åŒ…å«æ—¶é—´æˆ³ï¼‰
            latest_file = sorted(matching_files)[-1]
            files[file_type] = latest_file
            print(f"âœ… æ‰¾åˆ° {file_type}: {os.path.basename(latest_file)}")
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ° {file_type} æ–‡ä»¶")
            files[file_type] = None
    
    return files


def load_analysis_data(files):
    """åŠ è½½åˆ†ææ•°æ®"""
    data = {}
    
    # åŠ è½½é€‰é¢˜å»ºè®®
    if files['topic_suggestions']:
        try:
            data['topics'] = pd.read_csv(files['topic_suggestions'])
            print(f"ğŸ“Š åŠ è½½é€‰é¢˜å»ºè®®: {len(data['topics'])} æ¡")
        except Exception as e:
            print(f"âŒ åŠ è½½é€‰é¢˜å»ºè®®å¤±è´¥: {e}")
            data['topics'] = None
    
    # åŠ è½½é«˜äº’åŠ¨å†…å®¹
    if files['high_engagement']:
        try:
            data['high_engagement'] = pd.read_csv(files['high_engagement'])
            print(f"ğŸ“Š åŠ è½½é«˜äº’åŠ¨å†…å®¹: {len(data['high_engagement'])} æ¡")
        except Exception as e:
            print(f"âŒ åŠ è½½é«˜äº’åŠ¨å†…å®¹å¤±è´¥: {e}")
            data['high_engagement'] = None
    
    # åŠ è½½å…³é”®è¯åˆ†æ
    if files['keywords_analysis']:
        try:
            data['keywords'] = pd.read_csv(files['keywords_analysis'])
            print(f"ğŸ“Š åŠ è½½å…³é”®è¯åˆ†æ: {len(data['keywords'])} æ¡")
        except Exception as e:
            print(f"âŒ åŠ è½½å…³é”®è¯åˆ†æå¤±è´¥: {e}")
            data['keywords'] = None
    
    return data


def extract_content_highlights(title, desc=""):
    """ä»æ ‡é¢˜å’Œæè¿°ä¸­æå–å†…å®¹äº®ç‚¹"""
    if not title or pd.isna(title):
        return ""
    
    title = str(title)
    desc = str(desc) if desc and not pd.isna(desc) else ""
    content = f"{title} {desc}".lower()
    
    # å®šä¹‰äº®ç‚¹å…³é”®è¯æ¨¡å¼
    highlight_patterns = {
        'æ•°å­—äº®ç‚¹': [r'\d+å¤©', r'\d+ä¸ª', r'\d+ç§', r'\d+åˆ†é’Ÿ', r'\d+æ¬¡'],
        'æ•ˆæœäº®ç‚¹': ['å‡è‚¥', 'å¡‘å½¢', 'ç˜¦èº«', 'å˜åŒ–', 'æ•ˆæœ', 'æ”¹å–„', 'æå‡'],
        'ä½“éªŒäº®ç‚¹': ['äº²æµ‹', 'çœŸå®', 'ä½“éªŒ', 'æ„Ÿå—', 'å¿ƒå¾—', 'åˆ†äº«'],
        'ä¸“ä¸šäº®ç‚¹': ['æ•™ç¨‹', 'æ•™å­¦', 'æŠ€å·§', 'æ–¹æ³•', 'æŒ‡å¯¼', 'ä¸“ä¸š'],
        'å¯¹æ¯”äº®ç‚¹': ['vs', 'å¯¹æ¯”', 'åŒºåˆ«', 'å“ªä¸ªå¥½', 'é€‰æ‹©'],
        'æƒ…æ„Ÿäº®ç‚¹': ['çˆ±äº†', 'ç»äº†', 'å¤ªå¥½', 'è¶…æ£’', 'æ¨è', 'å¿…çœ‹']
    }
    
    highlights = []
    
    for category, patterns in highlight_patterns.items():
        for pattern in patterns:
            if re.search(pattern, content):
                highlights.append(category.replace('äº®ç‚¹', ''))
                break
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç‰¹å®šäº®ç‚¹ï¼Œå°è¯•æå–æ•°å­—æˆ–å…³é”®è¯
    if not highlights:
        # æå–æ•°å­—
        numbers = re.findall(r'\d+', title)
        if numbers:
            highlights.append(f"{numbers[0]}ä¸ªè¦ç‚¹")
        
        # æå–åŠ¨è¯
        action_words = ['å­¦ä¼š', 'æŒæ¡', 'äº†è§£', 'ä½“éªŒ', 'å°è¯•', 'ç»ƒä¹ ']
        for word in action_words:
            if word in content:
                highlights.append(f"{word}æ–¹æ³•")
                break
    
    return "ã€".join(highlights[:2]) if highlights else ""


def generate_content_calendar(data, days=30):
    """ç”Ÿæˆå†…å®¹æ—¥å†"""
    print(f"ğŸ“… ç”Ÿæˆ {days} å¤©å†…å®¹æ—¥å†...")
    
    calendar_entries = []
    
    # ç”Ÿæˆæ—¥æœŸåˆ—è¡¨ï¼ˆä»ä»Šå¤©å¼€å§‹çš„æœªæ¥30å¤©ï¼‰
    start_date = datetime.now().date()
    dates = [start_date + timedelta(days=i) for i in range(days)]
    
    # å‡†å¤‡æ•°æ®æº
    topics = data.get('topics')
    high_engagement = data.get('high_engagement')
    keywords = data.get('keywords')
    
    # è·å–å‰5ä¸ªé«˜é¢‘å…³é”®è¯
    top_keywords = []
    if keywords is not None and len(keywords) > 0:
        top_keywords = keywords.head(5)['å…³é”®è¯'].tolist()
    
    # é»˜è®¤ç›®æ ‡äººç¾¤
    target_audiences = ['å®å¦ˆ', 'å¥èº«åˆå­¦è€…', 'ä¸Šç­æ—', 'å­¦ç”Ÿå…š', 'æ–°æ‰‹å¦ˆå¦ˆ', 'èŒåœºå¥³æ€§']
    
    # ç”Ÿæˆå†…å®¹æ—¥å†æ¡ç›®
    for i, date in enumerate(dates):
        entry = {}
        
        # æ—¥æœŸ
        entry['Date'] = date.strftime('%Y-%m-%d')
        
        # ä¸»é¢˜æ–¹å‘
        if topics is not None and len(topics) > 0:
            topic_idx = i % len(topics)
            topic_row = topics.iloc[topic_idx]
            entry['ä¸»é¢˜æ–¹å‘'] = topic_row.get('type', 'é€šç”¨å†…å®¹')
        else:
            # é»˜è®¤ä¸»é¢˜æ–¹å‘
            default_topics = ['ä½“éªŒåˆ†äº«', 'æ•™ç¨‹æŒ‡å¯¼', 'å¯¹æ¯”æµ‹è¯„', 'çŸ¥è¯†ç§‘æ™®', 'æ‰“å¡è®°å½•']
            entry['ä¸»é¢˜æ–¹å‘'] = default_topics[i % len(default_topics)]
        
        # æ ‡é¢˜è‰ç¨¿
        if high_engagement is not None and len(high_engagement) > 0:
            title_idx = i % len(high_engagement)
            title_row = high_engagement.iloc[title_idx]
            original_title = title_row.get('title', '')
            
            # å¯¹åŸæ ‡é¢˜è¿›è¡Œç®€å•æ”¹å†™ï¼Œé¿å…å®Œå…¨é‡å¤
            if original_title:
                # ç®€å•çš„æ ‡é¢˜å˜åŒ–ç­–ç•¥
                variations = [
                    f"æˆ‘çš„{original_title}",
                    f"{original_title}ï½œçœŸå®ä½“éªŒ",
                    f"åˆ†äº«ï¼š{original_title}",
                    f"{original_title}ï¼ˆè¯¦ç»†ç‰ˆï¼‰",
                    original_title  # ä¿ç•™åŸæ ‡é¢˜
                ]
                entry['æ ‡é¢˜è‰ç¨¿'] = random.choice(variations)
                
                # æå–å†…å®¹äº®ç‚¹
                desc = title_row.get('desc', '') if 'desc' in title_row else ''
                entry['å†…å®¹äº®ç‚¹'] = extract_content_highlights(original_title, desc)
                
                # ç¬”è®°é“¾æ¥
                entry['ç¬”è®°é“¾æ¥'] = title_row.get('note_url', '') if 'note_url' in title_row else ''
            else:
                entry['æ ‡é¢˜è‰ç¨¿'] = f"ç¬¬{i+1}å¤©å†…å®¹åˆ†äº«"
                entry['å†…å®¹äº®ç‚¹'] = ""
                entry['ç¬”è®°é“¾æ¥'] = ""
        else:
            entry['æ ‡é¢˜è‰ç¨¿'] = f"ç¬¬{i+1}å¤©å†…å®¹åˆ†äº«"
            entry['å†…å®¹äº®ç‚¹'] = ""
            entry['ç¬”è®°é“¾æ¥'] = ""
        
        # å…³é”®è¯æ ‡ç­¾
        if top_keywords:
            # éšæœºé€‰æ‹©2-3ä¸ªå…³é”®è¯
            selected_keywords = random.sample(top_keywords, min(3, len(top_keywords)))
            entry['å…³é”®è¯æ ‡ç­¾'] = "ã€".join(selected_keywords)
        else:
            entry['å…³é”®è¯æ ‡ç­¾'] = "æ™®æ‹‰æã€è¿åŠ¨ã€å¥èº«"
        
        # ç›®æ ‡äººç¾¤ï¼ˆéšæœºé€‰æ‹©1-2ä¸ªï¼‰
        num_audiences = random.randint(1, 2)
        selected_audiences = random.sample(target_audiences, num_audiences)
        entry['ç›®æ ‡äººç¾¤'] = "ã€".join(selected_audiences)
        
        # å‘å¸ƒçŠ¶æ€
        entry['å‘å¸ƒçŠ¶æ€'] = "å¾…å†™"
        
        calendar_entries.append(entry)
    
    return pd.DataFrame(calendar_entries)


def optimize_calendar_distribution(calendar_df):
    """ä¼˜åŒ–å†…å®¹æ—¥å†åˆ†å¸ƒ"""
    print("ğŸ”§ ä¼˜åŒ–å†…å®¹åˆ†å¸ƒ...")
    
    # ç¡®ä¿ä¸»é¢˜æ–¹å‘åˆ†å¸ƒå‡åŒ€
    unique_topics = calendar_df['ä¸»é¢˜æ–¹å‘'].unique()
    
    # é‡æ–°åˆ†é…ä¸»é¢˜ï¼Œç¡®ä¿åˆ†å¸ƒæ›´å‡åŒ€
    for i, topic in enumerate(unique_topics):
        # æ¯ä¸ªä¸»é¢˜åˆ†é…åˆ°å¯¹åº”çš„æ—¥æœŸ
        topic_indices = list(range(i, len(calendar_df), len(unique_topics)))
        calendar_df.loc[topic_indices, 'ä¸»é¢˜æ–¹å‘'] = topic
    
    # ç¡®ä¿å‘¨æœ«æœ‰æ›´è½»æ¾çš„å†…å®¹
    for idx, row in calendar_df.iterrows():
        date_obj = datetime.strptime(row['Date'], '%Y-%m-%d')
        weekday = date_obj.weekday()
        
        # å‘¨æœ«ï¼ˆå‘¨å…­æ—¥ï¼‰å®‰æ’è½»æ¾å†…å®¹
        if weekday >= 5:  # 5=å‘¨å…­, 6=å‘¨æ—¥
            if 'æ•™ç¨‹' in row['ä¸»é¢˜æ–¹å‘'] or 'å¯¹æ¯”' in row['ä¸»é¢˜æ–¹å‘']:
                calendar_df.loc[idx, 'ä¸»é¢˜æ–¹å‘'] = 'æ‰“å¡åˆ†äº«'
                calendar_df.loc[idx, 'æ ‡é¢˜è‰ç¨¿'] = f"å‘¨æœ«æ”¾æ¾ï½œ{row['æ ‡é¢˜è‰ç¨¿']}"
    
    return calendar_df


def add_content_suggestions(calendar_df):
    """æ·»åŠ å†…å®¹å»ºè®®"""
    print("ğŸ’¡ æ·»åŠ å†…å®¹å»ºè®®...")
    
    # ä¸ºæ¯ä¸ªæ¡ç›®æ·»åŠ å†…å®¹å»ºè®®
    suggestions = []
    
    for _, row in calendar_df.iterrows():
        topic = row['ä¸»é¢˜æ–¹å‘']
        
        if 'ä½“éªŒ' in topic:
            suggestion = "åˆ†äº«ä¸ªäººçœŸå®ä½“éªŒï¼ŒåŒ…å«å‰åå¯¹æ¯”"
        elif 'æ•™ç¨‹' in topic:
            suggestion = "æä¾›è¯¦ç»†æ­¥éª¤ï¼Œé…å›¾æˆ–è§†é¢‘æ¼”ç¤º"
        elif 'å¯¹æ¯”' in topic:
            suggestion = "å®¢è§‚åˆ†æä¼˜ç¼ºç‚¹ï¼Œç»™å‡ºæ˜ç¡®å»ºè®®"
        elif 'ç§‘æ™®' in topic:
            suggestion = "ç”¨é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šä¸“ä¸šçŸ¥è¯†"
        elif 'æ‰“å¡' in topic:
            suggestion = "è®°å½•æ—¥å¸¸ç»ƒä¹ ï¼Œå±•ç¤ºåšæŒè¿‡ç¨‹"
        else:
            suggestion = "ç»“åˆä¸ªäººç»éªŒï¼Œæä¾›å®ç”¨ä»·å€¼"
        
        suggestions.append(suggestion)
    
    calendar_df['å†…å®¹å»ºè®®'] = suggestions
    
    return calendar_df


def save_notion_calendar(calendar_df, output_path):
    """ä¿å­˜ Notion å†…å®¹æ—¥å†"""
    print(f"ğŸ’¾ ä¿å­˜ Notion å†…å®¹æ—¥å†åˆ°: {output_path}")
    
    # ç¡®ä¿åˆ—é¡ºåºç¬¦åˆ Notion å¯¼å…¥è¦æ±‚
    column_order = [
        'Date', 'ä¸»é¢˜æ–¹å‘', 'æ ‡é¢˜è‰ç¨¿', 'å…³é”®è¯æ ‡ç­¾', 
        'ç›®æ ‡äººç¾¤', 'å†…å®¹äº®ç‚¹', 'å†…å®¹å»ºè®®', 'ç¬”è®°é“¾æ¥', 'å‘å¸ƒçŠ¶æ€'
    ]
    
    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    calendar_df = calendar_df[column_order]
    
    # ä¿å­˜ä¸º CSV
    calendar_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… æˆåŠŸç”Ÿæˆ {len(calendar_df)} æ¡å†…å®¹æ—¥å†è®°å½•")
    
    return calendar_df


def generate_summary_report(calendar_df, output_dir):
    """ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š"""
    print("ğŸ“‹ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = os.path.join(output_dir, f'notion_calendar_report_{timestamp}.txt')
    
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("Notion å†…å®¹æ—¥å†ç”ŸæˆæŠ¥å‘Š\n")
        f.write("=" * 60 + "\n\n")
        
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"æ—¥å†æ¡ç›®æ•°é‡: {len(calendar_df)}\n")
        f.write(f"æ—¥æœŸèŒƒå›´: {calendar_df['Date'].min()} åˆ° {calendar_df['Date'].max()}\n\n")
        
        # ä¸»é¢˜æ–¹å‘åˆ†å¸ƒ
        f.write("ğŸ“Š ä¸»é¢˜æ–¹å‘åˆ†å¸ƒ:\n")
        f.write("-" * 30 + "\n")
        topic_counts = calendar_df['ä¸»é¢˜æ–¹å‘'].value_counts()
        for topic, count in topic_counts.items():
            percentage = count / len(calendar_df) * 100
            f.write(f"{topic}: {count}æ¡ ({percentage:.1f}%)\n")
        
        # ç›®æ ‡äººç¾¤åˆ†å¸ƒ
        f.write("\nğŸ‘¥ ç›®æ ‡äººç¾¤åˆ†å¸ƒ:\n")
        f.write("-" * 30 + "\n")
        all_audiences = []
        for audiences in calendar_df['ç›®æ ‡äººç¾¤']:
            all_audiences.extend(audiences.split('ã€'))
        
        from collections import Counter
        audience_counts = Counter(all_audiences)
        for audience, count in audience_counts.most_common():
            f.write(f"{audience}: {count}æ¬¡\n")
        
        # å…³é”®è¯ä½¿ç”¨æƒ…å†µ
        f.write("\nğŸ”¤ å…³é”®è¯ä½¿ç”¨æƒ…å†µ:\n")
        f.write("-" * 30 + "\n")
        all_keywords = []
        for keywords in calendar_df['å…³é”®è¯æ ‡ç­¾']:
            all_keywords.extend(keywords.split('ã€'))
        
        keyword_counts = Counter(all_keywords)
        for keyword, count in keyword_counts.most_common(10):
            f.write(f"{keyword}: {count}æ¬¡\n")
        
        f.write(f"\n\næŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")
    
    return report_path


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='ç”Ÿæˆ Notion å†…å®¹æ—¥å†å¯¼å…¥ç”¨çš„ CSV æ–‡ä»¶',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python analysis/export_notionsheet.py
  python analysis/export_notionsheet.py --output-dir output --days 45
  python analysis/export_notionsheet.py --input-dir analysis_results
        """
    )

    parser.add_argument(
        '--input-dir', '-i',
        type=str,
        default='output',
        help='åˆ†æç»“æœè¾“å…¥ç›®å½• (é»˜è®¤: output)'
    )
    parser.add_argument(
        '--output-dir', '-o',
        type=str,
        default='output',
        help='è¾“å‡ºç›®å½• (é»˜è®¤: output)'
    )
    parser.add_argument(
        '--days', '-d',
        type=int,
        default=30,
        help='ç”Ÿæˆæ—¥å†çš„å¤©æ•° (é»˜è®¤: 30)'
    )
    parser.add_argument(
        '--filename',
        type=str,
        default='notion_content_calendar.csv',
        help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: notion_content_calendar.csv)'
    )

    args = parser.parse_args()

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        sys.exit(1)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    print("=" * 60)
    print("ğŸ“… Notion å†…å®¹æ—¥å†ç”Ÿæˆå™¨")
    print("=" * 60)

    try:
        # æŸ¥æ‰¾åˆ†ææ–‡ä»¶
        print(f"ğŸ” åœ¨ç›®å½•ä¸­æŸ¥æ‰¾åˆ†ææ–‡ä»¶: {args.input_dir}")
        analysis_files = find_latest_analysis_files(args.input_dir)

        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°å¿…è¦æ–‡ä»¶
        if not any(analysis_files.values()):
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•åˆ†ææ–‡ä»¶")
            print("è¯·å…ˆè¿è¡Œæ•°æ®åˆ†ææ¨¡å—ç”Ÿæˆå¿…è¦çš„æ–‡ä»¶")
            sys.exit(1)

        # åŠ è½½åˆ†ææ•°æ®
        print("\nğŸ“– åŠ è½½åˆ†ææ•°æ®...")
        data = load_analysis_data(analysis_files)

        # ç”Ÿæˆå†…å®¹æ—¥å†
        print(f"\nğŸ“… ç”Ÿæˆ {args.days} å¤©å†…å®¹æ—¥å†...")
        calendar_df = generate_content_calendar(data, args.days)

        # ä¼˜åŒ–å†…å®¹åˆ†å¸ƒ
        calendar_df = optimize_calendar_distribution(calendar_df)

        # æ·»åŠ å†…å®¹å»ºè®®
        calendar_df = add_content_suggestions(calendar_df)

        # ä¿å­˜ Notion æ—¥å†
        output_path = os.path.join(args.output_dir, args.filename)
        calendar_df = save_notion_calendar(calendar_df, output_path)

        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        report_path = generate_summary_report(calendar_df, args.output_dir)

        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 60)
        print("ğŸ“Š ç”Ÿæˆç»“æœç»Ÿè®¡")
        print("=" * 60)
        print(f"ğŸ“… æ—¥å†æ¡ç›®æ•°é‡: {len(calendar_df)}")
        print(f"ğŸ“† æ—¥æœŸèŒƒå›´: {calendar_df['Date'].min()} åˆ° {calendar_df['Date'].max()}")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Š: {report_path}")

        # æ˜¾ç¤ºä¸»é¢˜åˆ†å¸ƒ
        print("\nğŸ“Š ä¸»é¢˜æ–¹å‘åˆ†å¸ƒ:")
        topic_counts = calendar_df['ä¸»é¢˜æ–¹å‘'].value_counts()
        for topic, count in topic_counts.head().items():
            percentage = count / len(calendar_df) * 100
            print(f"  {topic}: {count}æ¡ ({percentage:.1f}%)")

        # æ˜¾ç¤ºå‰å‡ æ¡ç¤ºä¾‹
        print("\nğŸ“ å‰5æ¡å†…å®¹é¢„è§ˆ:")
        for i, (_, row) in enumerate(calendar_df.head().iterrows(), 1):
            print(f"  {i}. {row['Date']} | {row['ä¸»é¢˜æ–¹å‘']} | {row['æ ‡é¢˜è‰ç¨¿'][:30]}...")

        print(f"\nâœ… Notion å†…å®¹æ—¥å†ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ’¡ å¯ç›´æ¥å°† {args.filename} å¯¼å…¥åˆ° Notion æ•°æ®åº“ä¸­")

    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
